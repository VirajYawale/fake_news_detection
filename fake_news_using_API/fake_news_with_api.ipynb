{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# i try with the api but i can't get proper api which give real-time news\n",
        "# here we don't do extract the data from api and stored it in csv file,  we make it like that is use the data and discard\n",
        "\n",
        "# this first two code:\n",
        "# So, how does it know it's fake or real?\n",
        "# Because it learned the difference from historical data:\n",
        "\n",
        "# Fake news may use clickbait, exaggerated words, or patterns of misinformation\n",
        "\n",
        "# Real news typically has more neutral language, structured format, and authentic terms\n",
        "\n",
        "# TF-IDF captures those subtle differences, and Logistic Regression learns which words or patterns are predictive of fake vs. real."
      ],
      "metadata": {
        "id": "q5G8XtPBJhWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load datasets\n",
        "df_fake = pd.read_csv(\"/content/drive/MyDrive/fake_news_detection/Fake.csv\")\n",
        "df_true = pd.read_csv(\"/content/drive/MyDrive/fake_news_detection/True.csv\")\n",
        "\n",
        "# Label the data\n",
        "df_fake['label'] = 0  # fake\n",
        "df_true['label'] = 1  # real\n",
        "\n",
        "# Combine and clean\n",
        "df = pd.concat([df_fake, df_true], ignore_index=True)\n",
        "df = df[['text', 'label']].dropna()\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate\n",
        "preds = model.predict(X_test_vec)\n",
        "accuracy = accuracy_score(y_test, preds)\n",
        "print(f\"‚úÖ Model accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Save model and vectorizer\n",
        "joblib.dump(model, \"model.pkl\")\n",
        "joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "print(\"‚úÖ model.pkl and vectorizer.pkl have been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2v_uyImnACk",
        "outputId": "9b1959cd-5dad-4419-b800-d50a80454cf9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model accuracy: 98.46%\n",
            "‚úÖ model.pkl and vectorizer.pkl have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.pkl ‚Äî Your trained Logistic Regression model\n",
        "\n",
        "# vectorizer.pkl ‚Äî Your fitted TF-IDF vectorizer - TF-IDF helps you figure out which words are important in a document ‚Äî but not too common."
      ],
      "metadata": {
        "id": "CmR6EYkvncSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Why It's Used in Fake News Detection:\n",
        "\n",
        "# Helps identify important keywords in real vs. fake articles\n",
        "\n",
        "# Transforms human language into something a machine learning model can understand\n",
        "\n",
        "\n",
        "# Once you've transformed your news articles using TF-IDF,\n",
        "# you need something to learn patterns and make predictions ‚Äî that‚Äôs where the model comes in.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n8fylxdToAtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Flow:\n",
        "#  News Text\n",
        "\n",
        "#  TF-IDF Vectorizer ‚Üí Numbers\n",
        "\n",
        "#  Model ‚Üí Learns patterns from labeled data\n",
        "\n",
        "#  Predicts: REAL or FAKE"
      ],
      "metadata": {
        "id": "45Jv05tCoiNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5juewTxktrj",
        "outputId": "24ded21f-0cbd-49b1-823d-e6982dddc086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¢ Checking real-time headlines using NewsAPI...\n",
            "\n",
            "1. NC court sides with GOP candidate in Supreme Court race - Axios The decision, if it stands, could ov...\n",
            "   ‚û§ ‚úÖ REAL NEWS (Confidence: 55.19%)\n",
            "\n",
            "2. ‚ÄòHands Off!‚Äô protests against Trump and Musk are planned across the US - AP News Opponents of Presid...\n",
            "   ‚û§ üö® FAKE NEWS (Confidence: 67.12%)\n",
            "\n",
            "‚úçÔ∏è You can now enter your own news to check (type 'exit' to quit):\n",
            "\n",
            "Enter news headline or article: SEATTLE/WASHINGTON (Reuters) - President Donald Trump called on the U.S. Postal Service on Friday to charge ‚Äúmuch more‚Äù to ship packages for Amazon (AMZN.O), picking another fight with an online retail giant he has criticized in the past.     ‚ÄúWhy is the United States Post Office, which is losing many billions of dollars a year, while charging Amazon and others so little to deliver their packages, making Amazon richer and the Post Office dumber and poorer? Should be charging MUCH MORE!‚Äù Trump wrote on Twitter.  The president‚Äôs tweet drew fresh attention to the fragile finances of the Postal Service at a time when tens of millions of parcels have just been shipped all over the country for the holiday season.  The U.S. Postal Service, which runs at a big loss, is an independent agency within the federal government and does not receive tax dollars for operating expenses, according to its website.  Package delivery has become an increasingly important part of its business as the Internet has led to a sharp decline in the amount of first-class letters. The president does not determine postal rates. They are set by the Postal Regulatory Commission, an independent government agency with commissioners selected by the president from both political parties. That panel raised prices on packages by almost 2 percent in November.  Amazon was founded by Jeff Bezos, who remains the chief executive officer of the retail company and is the richest person in the world, according to Bloomberg News. Bezos also owns The Washington Post, a newspaper Trump has repeatedly railed against in his criticisms of the news media. In tweets over the past year, Trump has said the ‚ÄúAmazon Washington Post‚Äù fabricated stories. He has said Amazon does not pay sales tax, which is not true, and so hurts other retailers, part of a pattern by the former businessman and reality television host of periodically turning his ire on big American companies since he took office in January. Daniel Ives, a research analyst at GBH Insights, said Trump‚Äôs comment could be taken as a warning to the retail giant. However, he said he was not concerned for Amazon. ‚ÄúWe do not see any price hikes in the future. However, that is a risk that Amazon is clearly aware of and (it) is building out its distribution (system) aggressively,‚Äù he said. Amazon has shown interest in the past in shifting into its own delivery service, including testing drones for deliveries. In 2015, the company spent $11.5 billion on shipping, 46 percent of its total operating expenses that year.  Amazon shares were down 0.86 percent to $1,175.90 by early afternoon. Overall, U.S. stock prices were down slightly on Friday.  Satish Jindel, president of ShipMatrix Inc, which analyzes shipping data, disputed the idea that the Postal Service charges less than United Parcel Service Inc (UPS.N) and FedEx Corp (FDX.N), the other biggest players in the parcel delivery business in the United States. Many customers get lower rates from UPS and FedEx than they would get from the post office for comparable services, he said. The Postal Service delivers about 62 percent of Amazon packages, for about 3.5 to 4 million a day during the current peak year-end holiday shipping season, Jindel said. The Seattle-based company and the post office have an agreement in which mail carriers take Amazon packages on the last leg of their journeys, from post offices to customers‚Äô doorsteps. Amazon‚Äôs No. 2 carrier is UPS, at 21 percent, and FedEx is third, with 8 percent or so, according to Jindel. Trump‚Äôs comment tapped into a debate over whether Postal Service pricing has kept pace with the rise of e-commerce, which has flooded the mail with small packages.Private companies like UPS have long claimed the current system unfairly undercuts their business. Steve Gaut, a spokesman for UPS, noted that the company values its ‚Äúproductive relationship‚Äù with the postal service, but that it has filed with the Postal Regulatory Commission its concerns about the postal service‚Äôs methods for covering costs. Representatives for Amazon, the White House, the U.S. Postal Service and FedEx declined comment or were not immediately available for comment on Trump‚Äôs tweet. According to its annual report, the Postal Service lost $2.74 billion this year, and its deficit has ballooned to $61.86 billion.  While the Postal Service‚Äôs revenue for first class mail, marketing mail and periodicals is flat or declining, revenue from package delivery is up 44 percent since 2014 to $19.5 billion in the fiscal year ended Sept. 30, 2017. But it also lost about $2 billion in revenue when a temporary surcharge expired in April 2016. According to a Government Accountability Office report in February, the service is facing growing personnel expenses, particularly $73.4 billion in unfunded pension and benefits liabilities. The Postal Service has not announced any plans to cut costs. By law, the Postal Service has to set prices for package delivery to cover the costs attributable to that service. But the postal service allocates only 5.5 percent of its total costs to its business of shipping packages even though that line of business is 28 percent of its total revenue.\n",
            "‚û§ ‚úÖ REAL NEWS (Confidence: 67.78%)\n",
            "\n",
            "Enter news headline or article: Donald Trump just signed the GOP tax scam into law. Of course, that meant that he invited all of his craven, cruel GOP sycophants down from their perches on Capitol Hill to celebrate in the Rose Garden at the White House. Now, that part is bad enough   celebrating tax cuts for a bunch of rich hedge fund managers and huge corporations at the expense of everyday Americans. Of course, Trump is beside himself with glee, as this represents his first major legislative win since he started squatting in the White House almost a year ago. Thanks to said glee, in true Trumpian style, he gave a free-wheeling address, and a most curious subject came up as Trump was thanking the goons from the Hill. Somehow, Trump veered away from tax cuts, and started talking about the Congressional baseball shooting that happened over the summer.In that shooting, Rep. Steve Scalise, who is also the House Majority Whip, was shot and almost lost his life. Thanks to this tragic and stunning act of political violence, Scalise had a long recovery; in fact he is still in physical therapy. But, of course, vain and looks-obsessed Trump decided that he would congratulate Scalise, not on his survival and on his miraculous recovery, but on the massive amount of weight Scalise lost while he was practically dying. And make no mistake   Scalise is VERY lucky to be alive. According to doctors, when he arrived at the hospital, Scalise was actually, quote, in  imminent risk of death.  Here is the quote, via Twitter:How stunningly tone deaf does one have to be to say something like that? I never thought I d say this about a Republican that I, by all reasonable accounts, absolutely loathe, but I feel sorry for him. I am sorry he got shot, and I am even sorrier that he now has to stand there and listen to that orange buffoon talk about him like that.I am sure that Scalise is a much tougher man than Trump, though. I am equally sure that he also knows that Trump is an international embarrassment and a crazy man who never should have been allowed anywhere near the White House.Featured image via Alex Wong/Getty Images\n",
            "‚û§ üö® FAKE NEWS (Confidence: 99.11%)\n",
            "\n",
            "Enter news headline or article: The following statements¬†were posted to the verified Twitter accounts of U.S. President Donald Trump, @realDonaldTrump and @POTUS.  The opinions expressed are his own.¬†Reuters has not edited the statements or confirmed their accuracy.  @realDonaldTrump : - Based on the fact that the very unfair and unpopular Individual Mandate has been terminated as part of our Tax Cut Bill, which essentially Repeals (over time) ObamaCare, the Democrats & Republicans will eventually come together and develop a great new HealthCare plan! [0658 EST] - WOW, @foxandfrlends ‚ÄúDossier is bogus. Clinton Campaign, DNC funded Dossier. FBI CANNOT (after all of this time) VERIFY CLAIMS IN DOSSIER OF RUSSIA/TRUMP COLLUSION. FBI TAINTED.‚Äù And they used this Crooked Hillary pile of garbage as the basis for going after the Trump Campaign! [0824 EST] - All signs are that business is looking really good for next year, only to be helped further by our Tax Cut Bill. Will be a great year for Companies and JOBS! Stock Market is poised for another year of SUCCESS! [17:17 EST] -- Source link: (bit.ly/2jBh4LU) (bit.ly/2jpEXYR)\n",
            "‚û§ ‚úÖ REAL NEWS (Confidence: 60.59%)\n",
            "\n",
            "Enter news headline or article: \"He's A Lunatic\": Thousands Protest Against Donald Trump Across US'Hands Off' Protest in US: The rallies also extended to some European capitals, where demonstrators voiced opposition to Trump and his aggressive trade policies. Agence France-Presse World News Apr 06, 2025 07:54 am IST Published On Apr 06, 2025 07:00 am IST Last Updated On Apr 06, 2025 07:54 am IST Read Time: 4 mins Share TwitterWhatsAppFacebookRedditEmail US 'Hands Off' Protest: Trump has angered many Americans by moving aggressively to downsize governmentWashington, United States: Tens of thousands of protesters flooded the streets of major US cities on Saturday to oppose the divisive policies of President Donald Trump, in the largest demonstrations since his return to the White House.  Opponents of the Republican president's policies -- from government staffing cuts to trade tariffs and eroding civil liberties -- rallied in Washington, New York, Houston, Florida, Colorado and Los Angeles, among other locations.  \"I am so angry, I'm so mad, all the time, yes. A bunch of privileged, white alleged rapists are controlling our country. It's not great,\" said New York painter Shaina Kesner, 43, joining a crowd marching through the heart of Manhattan.  In Washington, thousands of demonstrators -- many traveling from across the United States -- gathered on the National Mall where dozens of speakers rallied opposition to Trump.\n",
            "‚û§ ‚úÖ REAL NEWS (Confidence: 67.78%)\n",
            "\n",
            "Enter news headline or article: Mumbai: Actress Raveena Tandon opened up about her deep emotional connection with the late legendary actor and filmmaker Manoj Kumar.  Reflecting on the special bond they shared, the Mohra actress revealed that she had been profoundly influenced by his legacy and the lessons he imparted through his work. Upon hearing the sad news of the actor's passing, Raveena visited Manoj Kumar's residence to meet his son and family.  Speaking to the media, she shared her special connection with the legendary actor and revealed that he had given her father his first break in the film industry. She shared how Manoj Kumar was not just a mentor to many in the industry but also like a father figure. Raveena also disclosed the final gift she intends to honor him with ‚Äî three cherished items that were dear to Manoj Kumar. These symbolic offerings include Mahakal's Rudraksha mala, Sai Baba's vibuti, and the Indian flag, which represent his deep love for India, spirituality, and patriotism.\n",
            "‚û§ üö® FAKE NEWS (Confidence: 89.47%)\n",
            "\n",
            "Enter news headline or article: exit\n",
            "üëã Exiting...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import joblib\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Load model and vectorizer\n",
        "model = joblib.load(\"model.pkl\")\n",
        "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# Prediction with confidence\n",
        "def check_news_realtime(news_text):\n",
        "    clean_text = preprocess(news_text)\n",
        "    vector = vectorizer.transform([clean_text])\n",
        "    prediction = model.predict(vector)[0]\n",
        "    confidence = max(model.predict_proba(vector)[0])\n",
        "    label = \"üö® FAKE NEWS\" if prediction == 0 else \"‚úÖ REAL NEWS\"\n",
        "    return f\"{label} (Confidence: {confidence:.2%})\"\n",
        "\n",
        "# Fetch full news (description + content)\n",
        "def fetch_latest_news(api_key, country=\"us\", page_size=5):\n",
        "    url = f\"https://newsapi.org/v2/top-headlines?country={country}&pageSize={page_size}&apiKey={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    articles = response.json().get(\"articles\", [])\n",
        "    news_texts = []\n",
        "\n",
        "    for article in articles:\n",
        "        title = article.get(\"title\", \"\")\n",
        "        description = article.get(\"description\", \"\")\n",
        "        content = article.get(\"content\", \"\")\n",
        "        full_text = f\"{title} {description} {content}\".strip()\n",
        "        if full_text:\n",
        "            news_texts.append(full_text)\n",
        "\n",
        "    return news_texts\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    API_KEY = \"ff190a48a285413e921b5a91343dd0cd\"\n",
        "\n",
        "    print(\"\\nüì¢ Checking real-time headlines using NewsAPI...\\n\")\n",
        "    news_list = fetch_latest_news(API_KEY)\n",
        "\n",
        "    for i, news in enumerate(news_list, 1):\n",
        "        result = check_news_realtime(news)\n",
        "        print(f\"{i}. {news[:100]}...\\n   ‚û§ {result}\\n\")  # show first 100 chars\n",
        "\n",
        "    print(\"‚úçÔ∏è You can now enter your own news to check (type 'exit' to quit):\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter news headline or article: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"üëã Exiting...\")\n",
        "            break\n",
        "        result = check_news_realtime(user_input)\n",
        "        print(f\"‚û§ {result}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7my6oSjVkxHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPl8VGc_ucgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9-laq_BucZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCJrcPPCucUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Preprocessing Function\n",
        "# -----------------------------\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Get Real News from API\n",
        "# -----------------------------\n",
        "def get_real_news_from_api(api_key, country=\"us\", page_size=100):\n",
        "    url = f\"https://newsapi.org/v2/top-headlines?country={country}&pageSize={page_size}&apiKey={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    articles = response.json().get(\"articles\", [])\n",
        "\n",
        "    news_data = []\n",
        "    for article in articles:\n",
        "        full_text = f\"{article.get('title', '')} {article.get('description', '')} {article.get('content', '')}\".strip()\n",
        "        if full_text:\n",
        "            news_data.append({\n",
        "                \"text\": full_text,\n",
        "                \"label\": 1,  # Real news\n",
        "                \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "            })\n",
        "    return pd.DataFrame(news_data)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Load Fake News from CSV\n",
        "# -----------------------------\n",
        "def load_fake_news(fake_csv_path):\n",
        "    df = pd.read_csv(fake_csv_path)\n",
        "    df = df[['text']].copy()\n",
        "    df['label'] = 0  # Fake news\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Train and Save Model\n",
        "# -----------------------------\n",
        "def train_and_save_model(fake_csv_path, api_key):\n",
        "    print(\"üîÑ Loading fake news...\")\n",
        "    fake_df = load_fake_news(fake_csv_path)\n",
        "    print(f\"‚úÖ Loaded {len(fake_df)} fake articles.\")\n",
        "\n",
        "    print(\"üåê Fetching real news from API...\")\n",
        "    real_df = get_real_news_from_api(api_key)\n",
        "    print(f\"‚úÖ Fetched {len(real_df)} real articles.\")\n",
        "\n",
        "    print(\"üßπ Preprocessing data...\")\n",
        "    fake_df['text'] = fake_df['text'].apply(preprocess)\n",
        "    real_df['text'] = real_df['text'].apply(preprocess)\n",
        "\n",
        "    # Combine and shuffle\n",
        "    df = pd.concat([real_df, fake_df], ignore_index=True)\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    print(\"üß† Training model with TF-IDF + Logistic Regression...\")\n",
        "    vectorizer = TfidfVectorizer(max_features=5000)\n",
        "    X = vectorizer.fit_transform(df['text'])\n",
        "    y = df['label']\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    print(\"üíæ Saving model and vectorizer...\")\n",
        "    joblib.dump(model, \"model.pkl\")\n",
        "    joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "    print(\"‚úÖ Model training complete. Files saved as model.pkl and vectorizer.pkl\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Predict User Input\n",
        "# -----------------------------\n",
        "def predict_user_input():\n",
        "    print(\"\\nüì∞ Enter a news headline or content to check:\")\n",
        "    user_input = input(\">>> \")\n",
        "\n",
        "    if not os.path.exists(\"model.pkl\") or not os.path.exists(\"vectorizer.pkl\"):\n",
        "        print(\"‚ùå Model files not found. Train the model first.\")\n",
        "        return\n",
        "\n",
        "    model = joblib.load(\"model.pkl\")\n",
        "    vectorizer = joblib.load(\"vectorizer.pkl\")\n",
        "\n",
        "    cleaned_text = preprocess(user_input)\n",
        "    vector = vectorizer.transform([cleaned_text])\n",
        "    prediction = model.predict(vector)[0]\n",
        "\n",
        "    result = \"üö® FAKE NEWS\" if prediction == 0 else \"‚úÖ REAL NEWS\"\n",
        "    print(f\"\\nPrediction: {result}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Run It All\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    FAKE_CSV_PATH = \"/content/drive/MyDrive/fake_news_detection/Fake.csv\"  # Update path if needed\n",
        "    API_KEY = \"37eaf5fe6f85b63687fd531a31428cd3\"  # Replace with your NewsAPI key\n",
        "\n",
        "    train_and_save_model(FAKE_CSV_PATH, API_KEY)\n",
        "    predict_user_input()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UylCFu6oucRX",
        "outputId": "eb794812-57c5-442e-9bf8-2dabe5ee0ed0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading fake news...\n",
            "‚úÖ Loaded 23481 fake articles.\n",
            "üåê Fetching real news from API...\n",
            "‚úÖ Fetched 32 real articles.\n",
            "üßπ Preprocessing data...\n",
            "üß† Training model with TF-IDF + Logistic Regression...\n",
            "üíæ Saving model and vectorizer...\n",
            "‚úÖ Model training complete. Files saved as model.pkl and vectorizer.pkl\n",
            "\n",
            "üì∞ Enter a news headline or content to check:\n",
            ">>> exit\n",
            "\n",
            "Prediction: üö® FAKE NEWS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKvAGy-Evkz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6oBILyHk1QQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "omM0guwl1QOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AOEicmgu1QMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ob5ZpUzb1QJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhkjubuc1QHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Preprocessing Function\n",
        "# -----------------------------\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Get Real News from MediaStack API\n",
        "# -----------------------------\n",
        "def get_real_news_from_api(access_key, limit=100):\n",
        "    url = f\"http://api.mediastack.com/v1/news?access_key={access_key}&languages=en&limit={limit}&sort=published_desc\"\n",
        "    response = requests.get(url)\n",
        "    articles = response.json().get(\"data\", [])\n",
        "\n",
        "    news_data = []\n",
        "    for article in articles:\n",
        "        full_text = f\"{article.get('title', '')} {article.get('description', '')}\".strip()\n",
        "        if full_text:\n",
        "            news_data.append({\n",
        "                \"text\": full_text,\n",
        "                \"label\": 1,\n",
        "                \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "            })\n",
        "    return pd.DataFrame(news_data)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Load Fake News from CSV\n",
        "# -----------------------------\n",
        "def load_fake_news(fake_csv_path):\n",
        "    df = pd.read_csv(fake_csv_path)\n",
        "    if 'text' not in df.columns:\n",
        "        raise KeyError(\"The CSV must have a 'text' column.\")\n",
        "    df = df[['text']].copy()\n",
        "    df['label'] = 0\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Train and Save Model\n",
        "# -----------------------------\n",
        "def train_and_save_model(fake_csv_path, access_key):\n",
        "    print(\"üîÑ Loading fake news...\")\n",
        "    fake_df = load_fake_news(fake_csv_path)\n",
        "    print(f\"‚úÖ Loaded {len(fake_df)} fake articles.\")\n",
        "\n",
        "    print(\"üåê Fetching real news from MediaStack API...\")\n",
        "    real_df = get_real_news_from_api(access_key)\n",
        "    print(f\"‚úÖ Fetched {len(real_df)} real articles.\")\n",
        "\n",
        "    print(\"üßπ Preprocessing data...\")\n",
        "    fake_df['text'] = fake_df['text'].apply(preprocess)\n",
        "    real_df['text'] = real_df['text'].apply(preprocess)\n",
        "\n",
        "    # Combine and shuffle\n",
        "    df = pd.concat([real_df, fake_df], ignore_index=True)\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    print(\"üß† Training model with TF-IDF + Logistic Regression...\")\n",
        "    vectorizer = TfidfVectorizer(max_features=5000)\n",
        "    X = vectorizer.fit_transform(df['text'])\n",
        "    y = df['label']\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    print(\"üíæ Saving model and vectorizer...\")\n",
        "    joblib.dump(model, \"model.pkl\")\n",
        "    joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "    print(\"‚úÖ Model training complete. Files saved as model.pkl and vectorizer.pkl\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Predict User Input\n",
        "# -----------------------------\n",
        "def predict_user_input():\n",
        "    print(\"\\nüì∞ Enter a news headline or content to check:\")\n",
        "    user_input = input(\">>> \")\n",
        "\n",
        "    if not os.path.exists(\"model.pkl\") or not os.path.exists(\"vectorizer.pkl\"):\n",
        "        print(\"‚ùå Model files not found. Train the model first.\")\n",
        "        return\n",
        "\n",
        "    model = joblib.load(\"model.pkl\")\n",
        "    vectorizer = joblib.load(\"vectorizer.pkl\")\n",
        "\n",
        "    cleaned_text = preprocess(user_input)\n",
        "    vector = vectorizer.transform([cleaned_text])\n",
        "    prediction = model.predict(vector)[0]\n",
        "\n",
        "    result = \"üö® FAKE NEWS\" if prediction == 0 else \"‚úÖ REAL NEWS\"\n",
        "    print(f\"\\nPrediction: {result}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Run It All\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    FAKE_CSV_PATH = \"/content/drive/MyDrive/fake_news_detection/Fake.csv\"  # Update with your file path\n",
        "    ACCESS_KEY = \"A61C9283-D0EA-492B-949B-AA07EE7BBA95\"  # üîë Replace with your MediaStack API key\n",
        "\n",
        "    train_and_save_model(FAKE_CSV_PATH, ACCESS_KEY)\n",
        "    predict_user_input()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF-rqhsB1QCH",
        "outputId": "49abe45e-2191-4175-e2d3-0532049d5230"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading fake news...\n",
            "‚úÖ Loaded 23481 fake articles.\n",
            "üåê Fetching real news from MediaStack API...\n",
            "‚úÖ Fetched 100 real articles.\n",
            "üßπ Preprocessing data...\n",
            "üß† Training model with TF-IDF + Logistic Regression...\n",
            "üíæ Saving model and vectorizer...\n",
            "‚úÖ Model training complete. Files saved as model.pkl and vectorizer.pkl\n",
            "\n",
            "üì∞ Enter a news headline or content to check:\n",
            ">>> Noida: An 18-month-old girl, kidnapped earlier this week, was rescued by police on Saturday in a swift operation that led to the arrest of a couple involved in the abduction. The police team was rewarded Rs 25,000 by the deputy commissioner of police (DCP), central Noida, for their prompt action. The accused, identified as Renu (44), a native of Aligarh, and Dinesh (28), from Hathras, had allegedly taken the child from Yusufpur Chak Shahberi without the mother's knowledge. DCP Shakti Mohan Avasthy said, \"On March 18, Bisrakh police received a complaint from the child's mother stating that her daughter was taken away by Renu and Dinesh, who worked as sweepers at 14G Avenue, Gaur City, on March 16. A case was registered under Section 358 (kidnapping from lawful guardianship) of the Bharatiya Nyaya Sanhita (BNS), and multiple teams were deployed to trace the child.\"\n",
            "\n",
            "Prediction: üö® FAKE NEWS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ntVSZHi-1cOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sH1tHTZ13xg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEy2T6Lt3xe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWA0IgU53xcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COP3mY9x3xaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import re\n",
        "import string\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Preprocessing Function\n",
        "# -----------------------------\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Get Real News from Twingly Livefeed\n",
        "# -----------------------------\n",
        "def get_real_news_from_twingly_livefeed(api_key, limit=100):\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    # Step 1: Get starting delivery_id from /status\n",
        "    try:\n",
        "        status_url = f\"https://data.twingly.net/news/b/livefeed/v1/status?apikey={api_key}\"\n",
        "        status_response = requests.get(status_url, headers=headers)\n",
        "        status_response.raise_for_status()\n",
        "        delivery_id = status_response.json()[\"latest_delivery_id\"]\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to get status: {e}\")\n",
        "        return pd.DataFrame(columns=[\"text\", \"label\", \"date\"])\n",
        "\n",
        "    # Step 2: Fetch real news using delivery_id\n",
        "    try:\n",
        "        feed_url = f\"https://data.twingly.net/news/b/livefeed/v1/feed?apikey={api_key}&since_id={delivery_id}\"\n",
        "        feed_response = requests.get(feed_url, headers=headers)\n",
        "        feed_response.raise_for_status()\n",
        "        articles = feed_response.json().get(\"posts\", [])\n",
        "\n",
        "        news_data = []\n",
        "        for article in articles[:limit]:\n",
        "            full_text = f\"{article.get('title', '')} {article.get('summary', '')}\".strip()\n",
        "            if full_text:\n",
        "                news_data.append({\n",
        "                    \"text\": full_text,\n",
        "                    \"label\": 1,\n",
        "                    \"date\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(news_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to fetch from Twingly Livefeed: {e}\")\n",
        "        return pd.DataFrame(columns=[\"text\", \"label\", \"date\"])\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Load Fake News from CSV\n",
        "# -----------------------------\n",
        "def load_fake_news(fake_csv_path):\n",
        "    df = pd.read_csv(fake_csv_path)\n",
        "    if 'text' not in df.columns:\n",
        "        raise KeyError(\"The CSV must have a 'text' column.\")\n",
        "    df = df[['text']].copy()\n",
        "    df['label'] = 0\n",
        "    return df\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Train and Save Model\n",
        "# -----------------------------\n",
        "def train_and_save_model(fake_csv_path, api_key):\n",
        "    print(\"üîÑ Loading fake news...\")\n",
        "    fake_df = load_fake_news(fake_csv_path)\n",
        "    print(f\"‚úÖ Loaded {len(fake_df)} fake articles.\")\n",
        "\n",
        "    print(\"üåê Fetching real news from Twingly Livefeed...\")\n",
        "    real_df = get_real_news_from_twingly_livefeed(api_key)\n",
        "    print(f\"‚úÖ Fetched {len(real_df)} real articles.\")\n",
        "\n",
        "    if real_df.empty:\n",
        "        print(\"‚ö†Ô∏è Real news dataset is empty. Aborting training to avoid bias.\")\n",
        "        return\n",
        "\n",
        "    print(\"üßπ Preprocessing data...\")\n",
        "    fake_df['text'] = fake_df['text'].apply(preprocess)\n",
        "    real_df['text'] = real_df['text'].apply(preprocess)\n",
        "\n",
        "    df = pd.concat([real_df, fake_df], ignore_index=True)\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    print(\"üß† Training model with TF-IDF + Logistic Regression...\")\n",
        "    vectorizer = TfidfVectorizer(max_features=5000)\n",
        "    X = vectorizer.fit_transform(df['text'])\n",
        "    y = df['label']\n",
        "\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X, y)\n",
        "\n",
        "    print(\"üíæ Saving model and vectorizer...\")\n",
        "    joblib.dump(model, \"model.pkl\")\n",
        "    joblib.dump(vectorizer, \"vectorizer.pkl\")\n",
        "    print(\"‚úÖ Model training complete. Files saved as model.pkl and vectorizer.pkl\")\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Predict User Input\n",
        "# -----------------------------\n",
        "def predict_user_input():\n",
        "    print(\"\\nüì∞ Enter a news headline or content to check:\")\n",
        "    user_input = input(\">>> \")\n",
        "\n",
        "    if not os.path.exists(\"model.pkl\") or not os.path.exists(\"vectorizer.pkl\"):\n",
        "        print(\"‚ùå Model files not found. Train the model first.\")\n",
        "        return\n",
        "\n",
        "    model = joblib.load(\"model.pkl\")\n",
        "    vectorizer = joblib.load(\"vectorizer.pkl\")\n",
        "\n",
        "    cleaned_text = preprocess(user_input)\n",
        "    vector = vectorizer.transform([cleaned_text])\n",
        "    prediction = model.predict(vector)[0]\n",
        "\n",
        "    result = \"üö® FAKE NEWS\" if prediction == 0 else \"‚úÖ REAL NEWS\"\n",
        "    print(f\"\\nPrediction: {result}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Run Everything\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    FAKE_CSV_PATH = \"/content/drive/MyDrive/fake_news_detection/Fake.csv\"  # Update path\n",
        "    API_KEY = \"A61C9283-D0EA-492B-949B-AA07EE7BBA95\"  # Your Twingly Livefeed API key\n",
        "\n",
        "    train_and_save_model(FAKE_CSV_PATH, API_KEY)\n",
        "    predict_user_input()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q73h4rgH3xX1",
        "outputId": "5605339e-dd1c-4efd-fbfc-5faaca8f630f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading fake news...\n",
            "‚úÖ Loaded 23481 fake articles.\n",
            "üåê Fetching real news from Twingly Livefeed...\n",
            "‚ùå Failed to fetch from Twingly Livefeed: 400 Client Error: Bad Request for url: https://data.twingly.net/news/b/livefeed/v1/feed?apikey=A61C9283-D0EA-492B-949B-AA07EE7BBA95&since_id=10138059155\n",
            "‚úÖ Fetched 0 real articles.\n",
            "‚ö†Ô∏è Real news dataset is empty. Aborting training to avoid bias.\n",
            "\n",
            "üì∞ Enter a news headline or content to check:\n",
            ">>> exit\n",
            "\n",
            "Prediction: üö® FAKE NEWS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnE9VHmr4GAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "perz-sldBY76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrYcu0uFBY5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHX10zpYBY2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IyZ4jwAGBiC-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}